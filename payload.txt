# Groq configuration

curl https://api.groq.com/openai/v1/chat/completions -s \
-H "Content-Type: application/json" \
-H "Authorization: Bearer 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" \
-d '{
"model": "meta-llama/llama-4-scout-17b-16e-instruct",
"messages": [{
    "role": "user",
    "content": "Explain the importance of fast language models"
}]
}'


# Together AI configuration 
import requests

url = "https://api.together.xyz/v1/chat/completions"

payload = {
    "model": "Qwen/Qwen2.5-72B-Instruct-Turbo",
    "context_length_exceeded_behavior": "error"
}
headers = {
    "accept": "application/json",
    "content-type": "application/json",
    "authorization": "Bearer default"
}

response = requests.post(url, json=payload, headers=headers)

print(response.text)